{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "import pytz\n",
    "def get_time_ranges(interval, old_start_time, old_end_time, date_format = \"%H:%M:%S.%f\", delta_period_type=\"minutes\"):\n",
    "    start_date = old_start_time\n",
    "    end_date = old_end_time+ timedelta(seconds = 1)\n",
    "    dates = []\n",
    "    while start_date < end_date:\n",
    "        delta_period_arg = {delta_period_type: interval}\n",
    "        interval_end = start_date + timedelta(**delta_period_arg)\n",
    "        if interval_end.time() < start_date.time():\n",
    "            dates.append({\"start_date\" : start_date.time(), \"end_date\" : datetime.max.time()})\n",
    "            if interval_end > end_date:\n",
    "                interval_end = end_date\n",
    "            interval_end = interval_end - timedelta(microseconds=1)\n",
    "            dates.append({\"start_date\" : datetime.min.time(), \"end_date\" : interval_end.time()})\n",
    "            start_date = start_date + timedelta(**delta_period_arg)\n",
    "            continue\n",
    "        if interval_end > end_date:\n",
    "            interval_end = end_date\n",
    "        interval_end = interval_end - timedelta(microseconds=1)\n",
    "        dates.append({\"start_date\" : start_date.time(), \"end_date\" : interval_end.time()})\n",
    "        start_date = start_date + timedelta(**delta_period_arg)\n",
    "    return dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_status_trend(store_id)-> list():\n",
    "    src1 = pd.read_csv(\"/Users/crest/Downloads/store status.csv\")\n",
    "    src2 = pd.read_csv(\"/Users/crest/Downloads/Menu hours.csv\")\n",
    "    src3 = pd.read_csv(\"/Users/crest/Downloads/bq-results-20230125-202210-1674678181880.csv\")\n",
    "    filtered_status = src1.query(f\"store_id == {store_id}\").reset_index()\n",
    "    filtered_timezone = src3.query(f\"store_id == {store_id}\").reset_index()\n",
    "    intervals = list()\n",
    "    trends = list() * 7\n",
    "    # print(datetime.strptime(filtered_status[\"timestamp_utc\"][0], \"%Y-%m-%d %H:%M:%S.%f UTC\").time())\n",
    "\n",
    "    local = None\n",
    "\n",
    "    if filtered_timezone.empty:\n",
    "        local = pytz.timezone(\"America/Chicago\")\n",
    "    else:\n",
    "        local = pytz.timezone(filtered_timezone[\"timezone_str\"][0])\n",
    "\n",
    "    for day in range(7):\n",
    "        start = None\n",
    "        end = None\n",
    "\n",
    "        filtered_time_range = src2.query(f\"store_id == {store_id} and day == {day}\").reset_index()\n",
    "\n",
    "        trends.append([])\n",
    "        intervals.append([])\n",
    "        if filtered_time_range.empty:\n",
    "            start = datetime.combine(datetime.today(), datetime.min.time())\n",
    "            end = datetime.combine(datetime.today(), datetime.max.time())\n",
    "\n",
    "        else:\n",
    "            start = datetime.strptime(filtered_time_range[\"start_time_local\"][0], \"%H:%M:%S\")\n",
    "            end = datetime.strptime(filtered_time_range[\"end_time_local\"][0], \"%H:%M:%S\")\n",
    "\n",
    "\n",
    "        new_start = start\n",
    "        local_dt = local.localize(new_start, is_dst=None)\n",
    "        start = local_dt.astimezone(pytz.utc)\n",
    "        \n",
    "\n",
    "        new_end = end\n",
    "        local_dt = local.localize(new_end, is_dst=None)\n",
    "        end = local_dt.astimezone(pytz.utc)   \n",
    "        # print(\"end\") \n",
    "        # print(f\"{end}  {new_end}\")\n",
    "\n",
    "\n",
    "        # print(f\"{end}\", end= \"\\n\\n\")\n",
    "        interval = get_time_ranges(15, start, end)\n",
    "        intervals.append(interval)\n",
    "        # print(interval)\n",
    "        # print(f\"start {start} end {end}\")\n",
    "        # print((end - start).total_seconds()/60)\n",
    "        max_interval_trend = [0] * len(interval)\n",
    "        for _, row in filtered_status.iterrows():\n",
    "            for index in range(len(interval)):\n",
    "                curr_time = datetime.strptime(row[\"timestamp_utc\"], \"%Y-%m-%d %H:%M:%S.%f UTC\").time()\n",
    "                if(interval[index][\"start_date\"] > interval[index][\"end_date\"]):\n",
    "                    if(curr_time < interval[index][\"start_date\"] \n",
    "                        and curr_time > interval[index][\"end_date\"]):\n",
    "                        continue\n",
    "                    if row[\"status\"] == \"active\":\n",
    "                        max_interval_trend[index] += 1\n",
    "                    else:\n",
    "                        max_interval_trend[index] -= 1\n",
    "                    break\n",
    "                else:\n",
    "                    if(curr_time >= interval[index][\"start_date\"] \n",
    "                        and curr_time < interval[index][\"end_date\"]):\n",
    "                        if row[\"status\"] == \"active\":\n",
    "                            max_interval_trend[index] += 1\n",
    "                        elif row[\"status\"] == \"inactive\":\n",
    "                            max_interval_trend[index] -= 1\n",
    "                        else:\n",
    "                            continue\n",
    "                        break\n",
    "        \n",
    "        for index in range(len(max_interval_trend)):\n",
    "            if not max_interval_trend[index]:\n",
    "                if not index:\n",
    "                    max_interval_trend[index] = 1\n",
    "                else:\n",
    "                    max_interval_trend[index] = max_interval_trend[index-1]\n",
    "        trends[day] = (max_interval_trend)\n",
    "\n",
    "    return trends, intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_ranges(start, end):\n",
    "    ranges = list()\n",
    "    while(start < end):\n",
    "        new_end = datetime.combine(start, datetime.max.time())\n",
    "        if new_end > end:\n",
    "            new_end = end\n",
    "        ranges.append({\"start\" : start, \"end\" : new_end})\n",
    "        start = new_end + timedelta(microseconds= 1)\n",
    "    return ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_uptime_and_downtime(ranges, trends, interval):\n",
    "    uptime = 0\n",
    "    downtime = 0\n",
    "    for range in ranges:\n",
    "        day = range[\"start\"].weekday()\n",
    "        index = 0\n",
    "        for time in interval[day]:\n",
    "            if range[\"start\"].time() > time[\"end_date\"]:\n",
    "                continue\n",
    "            if range[\"start\"].time() <= time[\"start_date\"]:\n",
    "                range[\"start\"] = datetime.combine(range[\"start\"], time[\"start_date\"])\n",
    "            \n",
    "            if range[\"start\"].time() >= time[\"start_date\"]:\n",
    "                if range[\"end\"].time() <= time[\"end_date\"]:\n",
    "                    if index < len(trends[day]) and trends[day][index] < 0:\n",
    "                        downtime += (range[\"end\"] - range[\"start\"]).total_seconds()\n",
    "                    else:\n",
    "                        uptime += (range[\"end\"] - range[\"start\"]).total_seconds()\n",
    "                    break\n",
    "                else:\n",
    "                    dt = datetime.combine(range[\"start\"], time[\"end_date\"])\n",
    "                    if dt < range[\"start\"]:\n",
    "                        dt = dt + timedelta(days = 1)\n",
    "                    if index < len(trends[day]) and trends[day][index] < 0:\n",
    "                        downtime += (dt - range[\"start\"]).total_seconds() \n",
    "                    else:\n",
    "                        uptime += (dt - range[\"start\"]).total_seconds()\n",
    "                    if index < len(interval[day]) - 1:\n",
    "                        range[\"start\"] = datetime.combine(range[\"start\"], interval[day][index+1][\"start_date\"])\n",
    "            index += 1\n",
    "    return uptime, downtime\n",
    "                    \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'start': datetime.datetime(2023, 8, 23, 11, 46, 36, 723001), 'end': datetime.datetime(2023, 8, 23, 12, 46, 36, 723001)}]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "14092"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "stores = set()\n",
    "src1 = Students.object.filter(store_id = \"dsdasd\")\n",
    "src1.groupby(\"storeId\")\n",
    "src1 = pd.read_csv(\"/Users/crest/Downloads/store status.csv\")\n",
    "for store in src1[\"store_id\"]:\n",
    "    stores.add(store)\n",
    "\n",
    "end = datetime.today().utcnow()\n",
    "start = end - timedelta(days= 6)\n",
    "ranges_week = generate_ranges(start, end)\n",
    "ranges_hour = generate_ranges(end - timedelta(hours= 1), end)\n",
    "ranges_day = generate_ranges(end - timedelta(days = 1), end)\n",
    "\n",
    "for store_id in stores:\n",
    "    trends, interval = calculate_status_trend(s\n",
    "                                              tore_id)\n",
    "    uptime_week, downtime_week = calculate_uptime_and_downtime(ranges_week, trends, interval)\n",
    "    uptime_day, downtime_day = calculate_uptime_and_downtime(ranges_day, trends, interval)\n",
    "    uptime_hour, downtime_hour = calculate_uptime_and_downtime(ranges_hour, trends, interval)\n",
    "    print(f\"{(uptime_hour) / 60}  {(downtime_hour)/60}\")\n",
    "    print(f\"{(uptime_day)/3600}   {(downtime_day)/3600}\")\n",
    "    print(f\"{(uptime_week)/3600}   {(downtime_week)/3600}\")\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['store_id', 'day', 'start_time_local', 'end_time_local']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "src1 = pd.read_csv(\"/Users/crest/Downloads/bq-results-20230125-202210-1674678181880.csv\")\n",
    "src1.columns.tolist()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
